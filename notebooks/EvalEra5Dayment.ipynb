{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downscaleing task: Era5 to Daymet 15 to 3.75 arcmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis code to implement the evaluation of downscaling. Before runnning this code, please make sure\n",
    "- you have already run inference script `inference_era5_daymet.py` to create inferenced dataset\n",
    "- make sure the script created files `groundtruth_0000.npy`, ... and `prediction_0000.npy`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RMSE\n",
    "    - RMSE for mean, $\\sigma_1, \\sigma_2, \\sigma_3$\n",
    "- R2\n",
    "- SSIM\n",
    "- Fourier diagram distance\n",
    "- PDF image:0\n",
    "- Scatter plot image:0\n",
    "- Taylor diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import gaussian_kde\n",
    "from skimage.metrics import structural_similarity as ssim # you may need to download skimage\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib import colors\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "#NOTE you may need to download cartopy besides `pip install -e .`\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from taylor import TaylorDiagram\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from psd import psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIABLE_NAMES= {\n",
    "    \"prcp\" : 'prcp'\n",
    "    # or \"tmin\": \"tmin\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lat and Lon from 3.75arcmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lat_weight(latitudes):\n",
    "    # Convert latitudes to radians and compute weights\n",
    "    lat_radians = np.deg2rad(latitudes)\n",
    "    weights = np.cos(lat_radians).clip(0., 1.)\n",
    "    print(\"Mean\", np.mean(weights))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get latlon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = np.load(\"/Users/ttt/Documents/projects/super-resolution/inference_era2daymet/15arcmin-3.75arcmin/lat.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_weights = get_lat_weight(lats)\n",
    "lat_weights = lat_weights[..., np.newaxis]\n",
    "lat_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = np.load(\"/Users/ttt/Documents/projects/super-resolution/inference_era2daymet/15arcmin-3.75arcmin/lon.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to your inference results\n",
    "basedatadir = \"/Users/ttt/Documents/projects/super-resolution/inference_era2daymet/15arcmin-3.75arcmin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['prcp']\n",
    "loss_metrics =  ['mse', 'imagegradient'] \n",
    "experiment_pairs = {\n",
    "    \"imagegradient\": ['3128692'],\n",
    "    \"mse\": ['3129425']\n",
    "}\n",
    "# assuming that the *.npy data is stored ...../{loss_metrics}/{variable}/{experiment_pairs}/test/*.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def get_data(truth_or_pred):\n",
    "    Var = {}\n",
    "    s1 = time.time()\n",
    "    for var in variables:\n",
    "        for l in loss_metrics:\n",
    "            expnames = experiment_pairs[l]\n",
    "            for expname in expnames:\n",
    "                print(f\"START: {var} {l} {expname} | {(time.time()-s1)/60.} [m]\")\n",
    "                filelist = sorted(glob.glob(\n",
    "                    os.path.join(*[basedatadir, l, var, expname, 'test',  f\"{truth_or_pred}*.npy\"])))\n",
    "                fname = os.path.join(*[basedatadir, l, var, expname, 'test', f\"{truth_or_pred}*.npy\"])\n",
    "                  \n",
    "                #assert len(filelist) > 0, f\"File Not Found {fname}\"\n",
    "                if len(filelist) > 0:\n",
    "\n",
    "                    data_array = None\n",
    "                    for idx, ifile in enumerate(filelist):\n",
    "                        data = np.load(ifile).astype(np.float32)   \n",
    "                    \n",
    "                        if idx > 0:\n",
    "                            data_array = np.concatenate([data_array, data], axis=0, dtype=np.float32)\n",
    "                        else:\n",
    "                            data_array = data\n",
    "            \n",
    "                    Var[f'{var}-{l}-{expname}'] = data_array\n",
    "    return Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict data\n",
    "Preds = {}\n",
    "Preds = get_data('prediction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Truths = {}\n",
    "Truths = get_data('groundtruth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_rmse(x, y, q):\n",
    "    \"\"\"\n",
    "        x: pred\n",
    "        y: truth \n",
    "        q: 0 - 1. 1,2,3 sigma = 0.6827, 0.9545, 0.9973  \n",
    "    \"\"\"\n",
    "    #0.6827, 0.9545, 0.9973\n",
    "    index = np.where(y>=np.quantile(y, q))\n",
    "    rmse =  np.sqrt(np.mean(np.square(x[index] -  y[index] )))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(float_array,vmax, vmin ):\n",
    "    # Normalize the array to range [0, 1]\n",
    "    norm_array = (float_array - vmin) / (vmax - vmin)\n",
    "\n",
    "    # Scale and convert to integers in range [0, 255]\n",
    "    int_array = (norm_array * 255).astype(np.uint8)\n",
    "    return int_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metrics = {}\n",
    "for (k, preds), (_, truths) in zip(Preds.items(),  Truths.items()):\n",
    "     \n",
    "    corrs = np.array([])\n",
    "    wrmses = np.array([])\n",
    "    s1rmses = np.array([])\n",
    "    s2rmses = np.array([])\n",
    "    s3rmses = np.array([])\n",
    "    ssim_scores = np.array([])\n",
    "    psnr_scores = np.array([])\n",
    "    \n",
    "    for pred, truth in zip(preds, truths ):\n",
    "        \n",
    "        corr = clim_pearsoner(x_sim=pred, x_obs=truth )\n",
    "        wrmse = lat_weight_rmse(x_sim=pred, x_obs=truth, lat_weights=lat_weights)\n",
    "        corrs = np.append(corrs, corr) \n",
    "        wrmses = np.append(wrmses, wrmse)\n",
    "        \n",
    "        # >1, 2, 3 sigma rmses\n",
    "        s1, s2, s3 = 0.6827, 0.9545, 0.9973\n",
    "        s1rmse = quantile_rmse(pred, truth, s1)\n",
    "        s2rmse = quantile_rmse(pred, truth, s2)\n",
    "        s3rmse = quantile_rmse(pred, truth, s3)\n",
    "        s1rmses = np.append(s1rmses, s1rmse)\n",
    "        s2rmses = np.append(s2rmses, s2rmse)\n",
    "        s3rmses = np.append(s3rmses, s3rmse)\n",
    "        \n",
    "        # transformation\n",
    "        vmin = min(np.nanmin(pred), np.nanmin(truth))\n",
    "        vmax = max(np.nanmax(pred), np.nanmax(truth))\n",
    "        pred= normalize(pred, vmax=vmax, vmin=vmin)\n",
    "        truth= normalize(truth, vmax=vmax, vmin=vmin)  \n",
    "    \n",
    "        # calc\n",
    "        _ssim = ssim(pred, truth)\n",
    "        _psnr = psnr(pred,truth)\n",
    "        ssim_scores = np.append(ssim_scores, _ssim)\n",
    "        psnr_scores = np.append(psnr_scores, _psnr)\n",
    "        \n",
    "    \n",
    "    # Add mean\n",
    "    corr_mean =  np.mean(corrs)\n",
    "    wrmse_mean= np.mean(wrmses)\n",
    "    ssim_mean = np.mean(ssim_scores)\n",
    "    psnr_mean = np.mean(psnr_scores)\n",
    "    s1rmse_mean = np.mean(s1rmses)\n",
    "    s2rmse_mean = np.mean(s2rmses)\n",
    "    s3rmse_mean = np.mean(s3rmses)\n",
    "    \n",
    "    # store at dict\n",
    "    Metrics[k] = {\n",
    "        'corr': corr_mean,  'rmse': wrmse_mean, \n",
    "        \"rmse_sigma1\": s1rmse_mean,\n",
    "        \"rmse_sigma2\": s2rmse_mean,\n",
    "        \"rmse_sigma3\": s3rmse_mean,\n",
    "        'ssim': ssim_mean, 'psnr': psnr_mean\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Metrics).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 100 #NOTE: max 365 i.e. the length of 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_RALSD(truths, preds, nsamples=-1):\n",
    "    return np.sqrt(np.mean(np.square(10*np.log(psd(truths[:nsamples])[0].mean() / \n",
    "                                    psd(preds[:nsamples])[0].mean()))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RALSDs = {}\n",
    "for (k, truths), (_, preds) in zip(Truths.items(), Preds.items()):\n",
    "    s1 = time.time()\n",
    "    RALSDs[k] = calc_RALSD(truths, preds, nsamples=nsamples)\n",
    "    print(f\"DONE {k} {(time.time() - s1)/60.0 } [min]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize fine-tune results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols=3\n",
    "nrows=1\n",
    "fts=14\n",
    "cbar_tick_size=12\n",
    "cbar_xlabel=12\n",
    "lons[lons>180] -= 360\n",
    "lonmin, lonmax = np.min(lons), np.max(lons)\n",
    "latmin, latmax = np.min(lats), np.max(lats)\n",
    "\n",
    "fig, axes = plt.subplots(nrows,ncols,figsize=(9.5*3/2, 4*nrows),\n",
    "                         subplot_kw={'projection': ccrs.PlateCarree(central_longitude=-100)})\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Define extracted colors (normalized RGB values)\n",
    "colors = [\n",
    "    (1.0, 1.0, 1.0), (0.7, 0.8, 0.75), (0.6, 0.75, 0.7),\n",
    "    (0.5, 0.7, 0.65), (0.3, 0.8, 0.8), (0.5, 0.6, 0.9), (0.75, 0.5, 0.95),\n",
    "    (0.85, 0.3, 0.85), (0.6, 0.1, 0.4), (0.2, 0.0, 0.2)\n",
    "]\n",
    "\n",
    "# Create custom colormap\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"custom_precipitation\", colors)\n",
    "\n",
    "for ax , tname, V, cbar_title_name in zip(\n",
    "        axes, ['Truth', 'Scratch (w Soil Moist) ', 'Fine-tune  \\n (w.o. soil moist & landcover)'],\n",
    "        [Truths['prcp-mse-3129425'][0],\n",
    "         Preds['prcp-mse-3129425'][0], \n",
    "         Preds['prcp-imagegradient-3128692'][0]], # Please change this lines\n",
    "        [r'$log_e(mm/day+1)$', r'$log_e(mm/day+1)$',  r'$log_e(mm/day+1)$']\n",
    "    ):\n",
    "    ax.set_extent([lonmin, lonmax, latmin, latmax], crs=ccrs.PlateCarree())\n",
    "    im = ax.imshow(V, cmap = custom_cmap, transform=ccrs.PlateCarree(), \n",
    "              extent=[lonmin, lonmax, latmin, latmax], vmin=0,\n",
    "              )\n",
    "    ax.set_title(tname, fontsize=fts)\n",
    "    ax.coastlines()  #Currently can be one of “110m”, “50m”, and “10m”.\n",
    "    \n",
    "    # grid format\n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(),\n",
    "                        draw_labels=True,)\n",
    "    gl.xlines = False\n",
    "    gl.ylines = False\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    gl.xlabel_style = {'size': 10, 'color': 'black'}\n",
    "    gl.ylabel_style = {'size': 10, 'color': 'black'}\n",
    "    cbar = plt.colorbar(im, ax=ax, orientation='horizontal', shrink=.75)\n",
    "    cbar.ax.set_xlabel(cbar_title_name, fontsize=cbar_xlabel)\n",
    "    cbar.ax.tick_params(labelsize=cbar_tick_size)\n",
    "\n",
    "figdir=\"./figs\"\n",
    "os.makedirs(figdir, exist_ok=True)\n",
    "plt.savefig(\"./figs/prcp_truth-predict_img0_2021_fine-tune-scratch-img_15-3.75arcmin.png\", dpi=140)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
